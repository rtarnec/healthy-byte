{"version":3,"sources":["../src/whisper.ts"],"sourcesContent":["/**\n * Copyright 2024 The Fire Company\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\nimport type { GenerateRequest, GenerateResponseData, Genkit } from 'genkit';\nimport { GenerationCommonConfigSchema, Message, z } from 'genkit';\nimport type { ModelAction } from 'genkit/model';\nimport { modelRef } from 'genkit/model';\nimport type OpenAI from 'openai';\nimport {\n  type TranscriptionCreateParams,\n  type Transcription,\n} from 'openai/resources/audio/index.mjs';\n\nexport const Whisper1ConfigSchema = GenerationCommonConfigSchema.extend({\n  language: z.string().optional(),\n  timestamp_granularities: z.array(z.enum(['word', 'segment'])).optional(),\n  response_format: z\n    .enum(['json', 'text', 'srt', 'verbose_json', 'vtt'])\n    .optional(),\n});\n\nexport const whisper1 = modelRef({\n  name: 'openai/whisper-1',\n  info: {\n    label: 'OpenAI - Whisper',\n    supports: {\n      media: true,\n      output: ['text', 'json'],\n      multiturn: false,\n      systemRole: false,\n      tools: false,\n    },\n  },\n  configSchema: Whisper1ConfigSchema,\n});\n\nexport const gpt4oTranscribe = modelRef({\n  name: 'openai/gpt-4o-transcribe',\n  info: {\n    label: 'OpenAI - GPT-4o Transcribe',\n    supports: {\n      media: true,\n      output: ['text', 'json'],\n      multiturn: false,\n      systemRole: false,\n      tools: false,\n    },\n  },\n  configSchema: Whisper1ConfigSchema,\n});\n\nfunction toWhisper1Request(\n  request: GenerateRequest<typeof Whisper1ConfigSchema>\n): TranscriptionCreateParams {\n  const message = new Message(request.messages[0]);\n  const media = message.media;\n  if (!media?.url) {\n    throw new Error('No media found in the request');\n  }\n  const mediaBuffer = Buffer.from(\n    media.url.slice(media.url.indexOf(',') + 1),\n    'base64'\n  );\n  const mediaFile = new File([mediaBuffer], 'input', {\n    type:\n      media.contentType ??\n      media.url.slice('data:'.length, media.url.indexOf(';')),\n  });\n  const options: TranscriptionCreateParams = {\n    model: 'whisper-1',\n    file: mediaFile,\n    prompt: message.text,\n    temperature: request.config?.temperature,\n    language: request.config?.language,\n    timestamp_granularities: request.config?.timestamp_granularities,\n  };\n  const outputFormat = request.output?.format as 'json' | 'text' | 'media';\n  const customFormat = request.config?.response_format;\n  if (outputFormat && customFormat) {\n    if (\n      outputFormat === 'json' &&\n      customFormat !== 'json' &&\n      customFormat !== 'verbose_json'\n    ) {\n      throw new Error(\n        `Custom response format ${customFormat} is not compatible with output format ${outputFormat}`\n      );\n    }\n  }\n  if (outputFormat === 'media') {\n    throw new Error(`Output format ${outputFormat} is not supported.`);\n  }\n  options.response_format = customFormat || outputFormat || 'text';\n  for (const k in options) {\n    if (options[k] === undefined) {\n      delete options[k];\n    }\n  }\n  return options;\n}\n\nfunction toGenerateResponse(\n  result: Transcription | string\n): GenerateResponseData {\n  return {\n    candidates: [\n      {\n        index: 0,\n        finishReason: 'stop',\n        message: {\n          role: 'model',\n          content: [\n            {\n              text: typeof result === 'string' ? result : result.text,\n            },\n          ],\n        },\n      },\n    ],\n  };\n}\n\nexport const SUPPORTED_STT_MODELS = {\n  'gpt-4o-transcribe': gpt4oTranscribe,\n  'whisper-1': whisper1,\n};\n\nexport function sttModel(\n  ai: Genkit,\n  name: string,\n  client: OpenAI\n): ModelAction<typeof Whisper1ConfigSchema> {\n  const modelId = `openai/${name}`;\n  const model = SUPPORTED_STT_MODELS[name];\n  if (!model) throw new Error(`Unsupported model: ${name}`);\n\n  return ai.defineModel<typeof Whisper1ConfigSchema>(\n    {\n      name: modelId,\n      ...model.info,\n      configSchema: model.configSchema,\n    },\n    async (request) => {\n      const params = toWhisper1Request(request);\n      // Explicitly setting stream to false ensures we use the non-streaming overload\n      const result = await client.audio.transcriptions.create({\n        ...params,\n        stream: false,\n      });\n      return toGenerateResponse(result);\n    }\n  );\n}\n"],"mappings":";;;;;AAgBA,SAAS,8BAA8B,SAAS,SAAS;AAEzD,SAAS,gBAAgB;AAOlB,MAAM,uBAAuB,6BAA6B,OAAO;AAAA,EACtE,UAAU,EAAE,OAAO,EAAE,SAAS;AAAA,EAC9B,yBAAyB,EAAE,MAAM,EAAE,KAAK,CAAC,QAAQ,SAAS,CAAC,CAAC,EAAE,SAAS;AAAA,EACvE,iBAAiB,EACd,KAAK,CAAC,QAAQ,QAAQ,OAAO,gBAAgB,KAAK,CAAC,EACnD,SAAS;AACd,CAAC;AAEM,MAAM,WAAW,SAAS;AAAA,EAC/B,MAAM;AAAA,EACN,MAAM;AAAA,IACJ,OAAO;AAAA,IACP,UAAU;AAAA,MACR,OAAO;AAAA,MACP,QAAQ,CAAC,QAAQ,MAAM;AAAA,MACvB,WAAW;AAAA,MACX,YAAY;AAAA,MACZ,OAAO;AAAA,IACT;AAAA,EACF;AAAA,EACA,cAAc;AAChB,CAAC;AAEM,MAAM,kBAAkB,SAAS;AAAA,EACtC,MAAM;AAAA,EACN,MAAM;AAAA,IACJ,OAAO;AAAA,IACP,UAAU;AAAA,MACR,OAAO;AAAA,MACP,QAAQ,CAAC,QAAQ,MAAM;AAAA,MACvB,WAAW;AAAA,MACX,YAAY;AAAA,MACZ,OAAO;AAAA,IACT;AAAA,EACF;AAAA,EACA,cAAc;AAChB,CAAC;AAED,SAAS,kBACP,SAC2B;AAjE7B;AAkEE,QAAM,UAAU,IAAI,QAAQ,QAAQ,SAAS,CAAC,CAAC;AAC/C,QAAM,QAAQ,QAAQ;AACtB,MAAI,EAAC,+BAAO,MAAK;AACf,UAAM,IAAI,MAAM,+BAA+B;AAAA,EACjD;AACA,QAAM,cAAc,OAAO;AAAA,IACzB,MAAM,IAAI,MAAM,MAAM,IAAI,QAAQ,GAAG,IAAI,CAAC;AAAA,IAC1C;AAAA,EACF;AACA,QAAM,YAAY,IAAI,KAAK,CAAC,WAAW,GAAG,SAAS;AAAA,IACjD,OACE,WAAM,gBAAN,YACA,MAAM,IAAI,MAAM,QAAQ,QAAQ,MAAM,IAAI,QAAQ,GAAG,CAAC;AAAA,EAC1D,CAAC;AACD,QAAM,UAAqC;AAAA,IACzC,OAAO;AAAA,IACP,MAAM;AAAA,IACN,QAAQ,QAAQ;AAAA,IAChB,cAAa,aAAQ,WAAR,mBAAgB;AAAA,IAC7B,WAAU,aAAQ,WAAR,mBAAgB;AAAA,IAC1B,0BAAyB,aAAQ,WAAR,mBAAgB;AAAA,EAC3C;AACA,QAAM,gBAAe,aAAQ,WAAR,mBAAgB;AACrC,QAAM,gBAAe,aAAQ,WAAR,mBAAgB;AACrC,MAAI,gBAAgB,cAAc;AAChC,QACE,iBAAiB,UACjB,iBAAiB,UACjB,iBAAiB,gBACjB;AACA,YAAM,IAAI;AAAA,QACR,0BAA0B,YAAY,yCAAyC,YAAY;AAAA,MAC7F;AAAA,IACF;AAAA,EACF;AACA,MAAI,iBAAiB,SAAS;AAC5B,UAAM,IAAI,MAAM,iBAAiB,YAAY,oBAAoB;AAAA,EACnE;AACA,UAAQ,kBAAkB,gBAAgB,gBAAgB;AAC1D,aAAW,KAAK,SAAS;AACvB,QAAI,QAAQ,CAAC,MAAM,QAAW;AAC5B,aAAO,QAAQ,CAAC;AAAA,IAClB;AAAA,EACF;AACA,SAAO;AACT;AAEA,SAAS,mBACP,QACsB;AACtB,SAAO;AAAA,IACL,YAAY;AAAA,MACV;AAAA,QACE,OAAO;AAAA,QACP,cAAc;AAAA,QACd,SAAS;AAAA,UACP,MAAM;AAAA,UACN,SAAS;AAAA,YACP;AAAA,cACE,MAAM,OAAO,WAAW,WAAW,SAAS,OAAO;AAAA,YACrD;AAAA,UACF;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAAA,EACF;AACF;AAEO,MAAM,uBAAuB;AAAA,EAClC,qBAAqB;AAAA,EACrB,aAAa;AACf;AAEO,SAAS,SACd,IACA,MACA,QAC0C;AAC1C,QAAM,UAAU,UAAU,IAAI;AAC9B,QAAM,QAAQ,qBAAqB,IAAI;AACvC,MAAI,CAAC,MAAO,OAAM,IAAI,MAAM,sBAAsB,IAAI,EAAE;AAExD,SAAO,GAAG;AAAA,IACR;AAAA,MACE,MAAM;AAAA,OACH,MAAM,OAFX;AAAA,MAGE,cAAc,MAAM;AAAA,IACtB;AAAA,IACA,CAAO,YAAY;AACjB,YAAM,SAAS,kBAAkB,OAAO;AAExC,YAAM,SAAS,MAAM,OAAO,MAAM,eAAe,OAAO,iCACnD,SADmD;AAAA,QAEtD,QAAQ;AAAA,MACV,EAAC;AACD,aAAO,mBAAmB,MAAM;AAAA,IAClC;AAAA,EACF;AACF;","names":[]}